name: Weekly Property Scraper

on:
  schedule:
    # Sunday 1:00 AM UTC — finishes well before Railway's 2:30 AM fallback retrain
    - cron: '0 1 * * 0'
  workflow_dispatch:  # allow manual runs from the Actions tab

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 180   # 3 h ceiling; typical run ~60-90 min

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install system dependencies for curl_cffi
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y --no-install-recommends \
            libcurl4-openssl-dev libssl-dev ca-certificates

      - name: Install Python dependencies
        run: |
          pip install --quiet \
            curl-cffi==0.7.1 \
            beautifulsoup4==4.12.0 \
            requests==2.31.0

      - name: Run scraper
        env:
          DATA_DIR: ${{ github.workspace }}/data/raw
        run: |
          mkdir -p data/raw
          echo "=== Starting MagicBricks scraper on GitHub Actions runner ==="
          echo "Runner IP: $(curl -s https://api.ipify.org)"
          python src/scrapers/magicbricks_scraper.py
          echo "=== Scraper finished ==="

      - name: Check output
        run: |
          JSONL="data/raw/magicbricks_all_cities.jsonl"
          if [ ! -f "$JSONL" ]; then
            echo "ERROR: No JSONL file produced — scraper may have failed entirely"
            exit 1
          fi
          LINES=$(wc -l < "$JSONL")
          SIZE=$(du -sh "$JSONL" | cut -f1)
          echo "Output: $LINES properties  |  $SIZE"
          if [ "$LINES" -lt 50 ]; then
            echo "WARNING: Very few properties scraped ($LINES) — still uploading but check logs"
          fi

      - name: Upload data to Railway and trigger retraining
        env:
          RAILWAY_API_KEY: ${{ secrets.RAILWAY_API_KEY }}
          RAILWAY_URL: ${{ secrets.RAILWAY_URL }}
        run: |
          JSONL="data/raw/magicbricks_all_cities.jsonl"
          LINES=$(wc -l < "$JSONL")
          echo "Uploading $LINES properties to $RAILWAY_URL/admin/ingest ..."
          HTTP_STATUS=$(curl -s -o /tmp/ingest_response.json -w "%{http_code}" \
            -X POST \
            -H "X-API-Key: $RAILWAY_API_KEY" \
            -H "Content-Type: application/x-ndjson" \
            --data-binary @"$JSONL" \
            --max-time 90 \
            "$RAILWAY_URL/admin/ingest")
          echo "HTTP status: $HTTP_STATUS"
          cat /tmp/ingest_response.json
          if [ "$HTTP_STATUS" != "200" ]; then
            echo "ERROR: Ingest endpoint returned $HTTP_STATUS"
            exit 1
          fi
          echo "=== Data uploaded; Railway is retraining in background ==="
