# Railway Deployment Architecture
## Real Estate Market Intelligence on realpoint.in

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ RAILWAY SERVICE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  FASTAPI SERVER (port 8000)                          â”‚   â”‚
â”‚  â”‚  â”œâ”€ GET  /api/estimate-price                        â”‚   â”‚
â”‚  â”‚  â”œâ”€ GET  /api/market-heatmap                        â”‚   â”‚
â”‚  â”‚  â”œâ”€ GET  /api/deals-this-week                       â”‚   â”‚
â”‚  â”‚  â”œâ”€ GET  /api/market-insights                       â”‚   â”‚
â”‚  â”‚  â””â”€ POST /admin/trigger-scraper (admin key)         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  APScheduler (Background Jobs)                       â”‚   â”‚
â”‚  â”‚  â”œâ”€ Every 7 days @ 2 AM UTC:                        â”‚   â”‚
â”‚  â”‚  â”‚  1. Run magicbricks_scraper.py                   â”‚   â”‚
â”‚  â”‚  â”‚  2. Run ML model retraining                      â”‚   â”‚
â”‚  â”‚  â”‚  3. Update API cache                            â”‚   â”‚
â”‚  â”‚  â””â”€ Logs: /data/logs/scheduler.log                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  DATA PERSISTENCE (Volume: /data)                   â”‚   â”‚
â”‚  â”‚  â”œâ”€ /data/raw/                                      â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€ magicbricks_all_cities.jsonl (1,378 props)  â”‚   â”‚
â”‚  â”‚  â”œâ”€ /data/models/                                  â”‚   â”‚
â”‚  â”‚  â”‚  â”œâ”€ price_predictor_rf.pkl                      â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€ encoders.pkl                                â”‚   â”‚
â”‚  â”‚  â””â”€ /data/logs/                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†‘                              â†‘
              â”‚                              â”‚
         requests/responses            updates every 7 days
              â”‚                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  REALPOINT.IN FRONTEND (Next.js)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Market Intelligence Dashboard                        â”‚  â”‚
â”‚  â”‚  â”œâ”€ Price Estimator Widget                           â”‚  â”‚
â”‚  â”‚  â”œâ”€ Market Heatmap (Location Rankings)              â”‚  â”‚
â”‚  â”‚  â””â”€ Deal Finder (This Week's Bargains)              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                               â”‚
â”‚  API Integration (Next.js /pages/api/proxy):               â”‚
â”‚  â”œâ”€ Caches responses 1 hour                              â”‚  â”‚
â”‚  â”œâ”€ No CORS issues (server-to-server)                    â”‚  â”‚
â”‚  â””â”€ Adds last-updated timestamp                          â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Railway Setup

### 1. Create Railway Service

```yaml
# railway.yaml (in root of repo)
services:
  api:
    build:
      dockerfile: Dockerfile
    environmentVariables:
      RAILWAY_VOLUME_MOUNT_PATH: /data
    volumes:
      - data:/data  # Persists across deployments
    ports:
      - 8000:8000
    env:
      LOG_DIR: /data/logs
      DATA_DIR: /data/raw
      MODEL_DIR: /data/models

volumes:
  data:
    driver: local
```

### 2. Dockerfile

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

# Create data directories
RUN mkdir -p /data/raw /data/models /data/logs

# Run FastAPI + APScheduler
CMD ["python", "src/railway/main.py"]
```

### 3. Railway Environment Variables

```
RAILWAY_VOLUME_MOUNT_PATH=/data
ADMIN_API_KEY=your-secret-key-here
FLASK_ENV=production
LOG_LEVEL=INFO
```

---

## ğŸš€ FastAPI Server Structure

### New File: `src/railway/main.py`

```python
from fastapi import FastAPI, HTTPException, Header
from fastapi.middleware.cors import CORSMiddleware
from apscheduler.schedulers.background import BackgroundScheduler
import pickle
import pandas as pd
import json
from pathlib import Path
from datetime import datetime
import os

app = FastAPI(title="PropertyIntel API")

# Add CORS for realpoint.in
app.add_middleware(
    CORSMiddleware,
    allow_origins=["realpoint.in", "*.realpoint.in"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Paths
DATA_DIR = Path(os.getenv("DATA_DIR", "/data/raw"))
MODEL_DIR = Path(os.getenv("MODEL_DIR", "/data/models"))
LOG_DIR = Path(os.getenv("LOG_DIR", "/data/logs"))
ADMIN_KEY = os.getenv("ADMIN_API_KEY", "default-key")

# Create directories
DATA_DIR.mkdir(parents=True, exist_ok=True)
MODEL_DIR.mkdir(parents=True, exist_ok=True)
LOG_DIR.mkdir(parents=True, exist_ok=True)

# Load models (on startup)
try:
    with open(MODEL_DIR / "price_predictor_rf.pkl", "rb") as f:
        model_rf = pickle.load(f)
    with open(MODEL_DIR / "encoders.pkl", "rb") as f:
        le_location, le_ptype = pickle.load(f)
    market_data = pd.read_json(DATA_DIR / "magicbricks_all_cities.jsonl", lines=True)
    print("âœ… Models loaded successfully")
except Exception as e:
    print(f"âŒ Failed to load models: {e}")

# ============================================================================
# API ENDPOINTS
# ============================================================================

@app.get("/health")
def health():
    """Health check"""
    return {
        "status": "OK",
        "timestamp": datetime.utcnow().isoformat(),
        "last_update": get_last_update_time()
    }

@app.get("/api/estimate-price")
def estimate_price(
    bhk: int,
    area_sqft: int,
    location: str = "Mumbai",
    property_type: str = "Apartment"
):
    """Estimate property price"""
    try:
        # Validation
        if not (1 <= bhk <= 5):
            raise HTTPException(status_code=400, detail="BHK must be 1-5")
        if not (300 <= area_sqft <= 10000):
            raise HTTPException(status_code=400, detail="Area must be 300-10000 sqft")
        
        # Encode
        try:
            loc_encoded = le_location.transform([location])[0]
        except:
            loc_encoded = le_location.transform(["Other"])[0]
        
        try:
            ptype_encoded = le_ptype.transform([property_type])[0]
        except:
            ptype_encoded = le_ptype.transform(["Apartment"])[0]
        
        # Get market avg price per sqft
        loc_data = market_data[market_data["location"].str.contains(location, case=False, na=False)]
        avg_price_per_sqft = loc_data["price_per_sqft"].mean() if len(loc_data) > 0 else market_data["price_per_sqft"].mean()
        
        # Predict
        import numpy as np
        X = np.array([[bhk, area_sqft, loc_encoded, ptype_encoded, avg_price_per_sqft]])
        predicted_price = model_rf.predict(X)[0]
        price_per_sqft = (predicted_price * 10_000_000) / area_sqft
        
        return {
            "property": {"bhk": bhk, "area_sqft": area_sqft, "location": location},
            "estimate": {
                "price_cr": round(predicted_price, 2),
                "price_per_sqft": round(price_per_sqft, 0),
                "confidence": 0.946,
                "model": "Random Forest"
            },
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/market-heatmap")
def market_heatmap():
    """Location rankings by price"""
    heatmap = []
    for location in market_data["location"].unique():
        loc_data = market_data[market_data["location"] == location]
        heatmap.append({
            "location": location,
            "avg_price_cr": round(loc_data["price_cr"].mean(), 2),
            "price_per_sqft": round(loc_data["price_per_sqft"].mean(), 0),
            "properties": len(loc_data)
        })
    
    return {
        "heatmap": sorted(heatmap, key=lambda x: x["price_per_sqft"], reverse=True),
        "last_updated": get_last_update_time()
    }

@app.get("/api/deals-this-week")
def deals_this_week(min_discount: int = 15):
    """Find properties 15%+ underpriced"""
    try:
        # Get predictions for all properties
        import numpy as np
        X_all = market_data[["bhk", "area_sqft", "location_encoded", "ptype_encoded", "price_per_sqft"]].values
        predicted = model_rf.predict(X_all)
        market_data["predicted_price"] = predicted
        
        # Find underpriced
        market_data["discount_pct"] = ((market_data["price_cr"] - market_data["predicted_price"]) / market_data["predicted_price"] * 100)
        deals = market_data[market_data["discount_pct"] > min_discount].nlargest(10, "area_sqft")
        
        return {
            "deals": [
                {
                    "location": row["location"],
                    "bhk": int(row["bhk"]),
                    "area_sqft": int(row["area_sqft"]),
                    "listed_price_cr": row["price_cr"],
                    "fair_value_cr": round(row["predicted_price"], 2),
                    "savings_cr": round(row["price_cr"] - row["predicted_price"], 2),
                    "discount_pct": round(row["discount_pct"], 1)
                }
                for _, row in deals.iterrows()
            ],
            "count": len(deals),
            "last_updated": get_last_update_time()
        }
    except Exception as e:
        return {"error": str(e), "deals": []}

@app.get("/api/market-insights")
def market_insights():
    """Overall market statistics"""
    return {
        "total_properties": len(market_data),
        "avg_price_cr": round(market_data["price_cr"].mean(), 2),
        "price_range": f"{market_data['price_cr'].min():.2f} - {market_data['price_cr'].max():.2f}",
        "locations_covered": int(market_data["location"].nunique()),
        "model_accuracy": 0.946,
        "last_updated": get_last_update_time(),
        "next_update": get_next_update_time()
    }

# ============================================================================
# ADMIN ENDPOINTS (Protected)
# ============================================================================

@app.post("/admin/trigger-scraper")
def trigger_scraper(x_api_key: str = Header(None)):
    """Manual trigger for scraper (admin only)"""
    if x_api_key != ADMIN_KEY:
        raise HTTPException(status_code=403, detail="Invalid API key")
    
    try:
        # Import and run scraper
        import sys
        sys.path.insert(0, "/app/src/scrapers")
        from magicbricks_scraper import scrape_infinite_parallel
        
        # Run with updated paths
        scrape_infinite_parallel(
            max_pages=15,
            enable_details=True,
            max_workers=2
        )
        
        # Reload models
        reload_models()
        
        return {"status": "Scraper completed", "timestamp": datetime.utcnow().isoformat()}
    except Exception as e:
        return {"status": "Error", "error": str(e)}

# ============================================================================
# BACKGROUND SCHEDULER
# ============================================================================

def run_weekly_update():
    """Run every 7 days: scrape + retrain + reload"""
    print(f"\n[{datetime.utcnow()}] Starting weekly update...")
    
    try:
        # Run scraper
        print("  1/3 Running scraper...")
        import sys
        sys.path.insert(0, "/app/src/scrapers")
        from magicbricks_scraper import scrape_infinite_parallel
        
        scrape_infinite_parallel(max_pages=15, enable_details=True, max_workers=2)
        
        # Retrain model
        print("  2/3 Retraining model...")
        import sys
        sys.path.insert(0, "/app/notebooks")
        # Would import and run training here
        
        # Reload models
        print("  3/3 Reloading models...")
        reload_models()
        
        print(f"[{datetime.utcnow()}] âœ… Weekly update completed")
        
    except Exception as e:
        print(f"[{datetime.utcnow()}] âŒ Weekly update failed: {e}")

def reload_models():
    """Reload models from disk"""
    global model_rf, le_location, le_ptype, market_data
    with open(MODEL_DIR / "price_predictor_rf.pkl", "rb") as f:
        model_rf = pickle.load(f)
    with open(MODEL_DIR / "encoders.pkl", "rb") as f:
        le_location, le_ptype = pickle.load(f)
    market_data = pd.read_json(DATA_DIR / "magicbricks_all_cities.jsonl", lines=True)

def get_last_update_time():
    """Get when data was last updated"""
    jsonl_file = DATA_DIR / "magicbricks_all_cities.jsonl"
    if jsonl_file.exists():
        return datetime.fromtimestamp(jsonl_file.stat().st_mtime).isoformat()
    return "Never"

def get_next_update_time():
    """Get when next update is scheduled"""
    # This should calculate based on scheduler
    return "In ~7 days"

# Initialize scheduler
scheduler = BackgroundScheduler()
scheduler.add_job(run_weekly_update, 'cron', day_of_week='0', hour='2', minute='0')  # Every Sunday 2 AM
scheduler.start()

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

---

## ğŸ¨ Next.js Integration (realpoint.in)

### Create: `pages/market-intelligence/dashboard.tsx`

```typescript
import { useState, useEffect } from 'react';

export default function MarketDashboard() {
  const [estimate, setEstimate] = useState(null);
  const [heatmap, setHeatmap] = useState([]);
  const [deals, setDeals] = useState([]);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    fetchMarketData();
  }, []);

  const fetchMarketData = async () => {
    try {
      // Fetch through Next.js API proxy (no CORS issues)
      const [heatmapRes, dealsRes] = await Promise.all([
        fetch('/api/proxy/market-heatmap'),
        fetch('/api/proxy/deals-this-week')
      ]);

      setHeatmap(await heatmapRes.json());
      setDeals(await dealsRes.json());
      setLoading(false);
    } catch (error) {
      console.error('Failed to fetch market data', error);
    }
  };

  const estimatePrice = async (bhk, area, location) => {
    const res = await fetch(
      `/api/proxy/estimate-price?bhk=${bhk}&area_sqft=${area}&location=${location}`
    );
    setEstimate(await res.json());
  };

  if (loading) return <div>Loading market intelligence...</div>;

  return (
    <div className="market-dashboard">
      <h1>Market Intelligence</h1>

      {/* Price Estimator Widget */}
      <section className="estimator">
        <h2>Price Estimator</h2>
        <input type="number" placeholder="BHK" />
        <input type="number" placeholder="Area (sqft)" />
        <select>
          <option>Mumbai</option>
          <option>Bangalore</option>
          <option>Delhi</option>
        </select>
        <button onClick={() => estimatePrice(3, 1500, 'Mumbai')}>
          Estimate Price
        </button>
        {estimate && <p>Fair Price: â‚¹{estimate.estimate.price_cr} Cr</p>}
      </section>

      {/* Market Heatmap */}
      <section className="heatmap">
        <h2>Market Heatmap</h2>
        <table>
          <thead>
            <tr>
              <th>Location</th>
              <th>Price/sqft</th>
              <th>Avg Price</th>
              <th>Properties</th>
            </tr>
          </thead>
          <tbody>
            {heatmap.heatmap?.map((loc) => (
              <tr key={loc.location}>
                <td>{loc.location}</td>
                <td>â‚¹{loc.price_per_sqft}</td>
                <td>â‚¹{loc.avg_price_cr} Cr</td>
                <td>{loc.properties}</td>
              </tr>
            ))}
          </tbody>
        </table>
      </section>

      {/* Deals This Week */}
      <section className="deals">
        <h2>Deals This Week (15%+ Discount)</h2>
        {deals.deals?.map((deal) => (
          <div key={deal.url} className="deal-card">
            <h3>{deal.location}</h3>
            <p>{deal.bhk} BHK â€¢ {deal.area_sqft} sqft</p>
            <p>
              Listed: â‚¹{deal.listed_price_cr} Cr | Fair: â‚¹{deal.fair_value_cr} Cr
            </p>
            <p className="savings">SAVE: â‚¹{deal.savings_cr} Cr ({deal.discount_pct}%)</p>
          </div>
        ))}
      </section>
    </div>
  );
}
```

### Create: `pages/api/proxy/[endpoint].ts`

```typescript
// Proxy requests to Railway API with caching
export default async function handler(req, res) {
  const { endpoint, ...params } = req.query;
  
  const railwayUrl = `${process.env.RAILWAY_API_URL}/api/${endpoint}`;
  const queryStr = new URLSearchParams(params).toString();
  
  try {
    const response = await fetch(`${railwayUrl}?${queryStr}`);
    const data = await response.json();
    
    // Cache for 1 hour
    res.setHeader('Cache-Control', 'public, s-maxage=3600');
    res.json(data);
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch from API' });
  }
}
```

---

## ğŸ“‹ Deployment Checklist

- [ ] Create Railway account
- [ ] Add repo to Railway
- [ ] Set environment variables (ADMIN_API_KEY, etc)
- [ ] Create `/data` volume
- [ ] Deploy Dockerfile
- [ ] Test endpoints: `curl https://your-railway-app.up.railway.app/health`
- [ ] Add API endpoint to Next.js environment: `RAILWAY_API_URL=...`
- [ ] Test dashboard on realpoint.in
- [ ] Monitor scheduler logs

---

## ğŸ” Security Notes

- Keep `ADMIN_API_KEY` secret
- Realpoint.in should use HTTPS
- Add rate limiting if needed: `from slowapi import Limiter`
- Monitor /data volume space

---

## ğŸ“Š What Users See on realpoint.in

1. **Dashboard Card:** "Market Intelligence"
   - Price Estimator form
   - Heatmap table
   - Last updated timestamp

2. **Integration Points:**
   - Property listing pages: Show "Fair Market Price" next to listings
   - Search results: Sort by "Best Deals" using the API
   - Agent tools: Price calculator widget

3. **Data Freshness:**
   - "Last updated: Feb 26, 2026"
   - "Next update: Mar 5, 2026"

---

## ğŸ¯ Success Criteria

âœ… API responds in <200ms
âœ… Heatmap shows all 8 locations
âœ… Estimated prices match 94.6% accuracy
âœ… Dashboard loads in realpoint.in
âœ… Scraper runs weekly automatically
âœ… Data persists across Railway restarts
